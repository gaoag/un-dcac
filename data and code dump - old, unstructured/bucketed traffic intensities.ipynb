{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import LocalCluster\n",
    "import dask.dataframe as dd\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lat = 19.595892\n",
    "origin_lat = 19.220471\n",
    "max_lon = -98.828109\n",
    "origin_lon = -99.438230\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xab.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaoag/anaconda3/lib/python3.6/site-packages/dask/dataframe/core.py:2067: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xau.csv\n",
      "xat.csv\n",
      "xac.csv\n",
      "xaa.csv\n",
      "xav.csv\n",
      "xaw.csv\n",
      "xas.csv\n",
      "xad.csv\n",
      "xae.csv\n",
      "xar.csv\n",
      "xap.csv\n",
      "xag.csv\n",
      "xaf.csv\n",
      "xaq.csv\n",
      "xak.csv\n",
      "xaj.csv\n",
      "xbf.csv\n",
      "xbd.csv\n",
      "xah.csv\n",
      "xai.csv\n",
      "xbe.csv\n",
      "xam.csv\n",
      "xaz.csv\n",
      "xba.csv\n",
      "xal.csv\n",
      "xan.csv\n",
      "xay.csv\n",
      "xbb.csv\n",
      "xbc.csv\n",
      "xax.csv\n",
      "xao.csv\n"
     ]
    }
   ],
   "source": [
    "directory = './sub_items/'\n",
    "for i, filename in enumerate(os.listdir(directory)):\n",
    "    if 'DS_Store' in filename:\n",
    "        continue\n",
    "    print(filename)\n",
    "    df = dd.read_csv(directory + filename, header=None, names=['endTime', 'startTime', 'level', 'x','y'])\n",
    "    #first, we cut out all the entries in our dataframe which don't fit the desired latitude/longitude.\n",
    "    df = df[(df['y'] < max_lat) & (df['y'] > origin_lat) & (df['x'] < max_lon) & (df['x'] > origin_lon)]\n",
    "\n",
    "    #next, we assign each row an x_bucket or y_bucket based upon its latitude and longitude.\n",
    "    lon_step_size = abs(max_lon - origin_lon)/500\n",
    "    lat_step_size = abs(max_lat - origin_lat)/500\n",
    "    df['x_bucket'] = df['x'].apply(lambda x: abs(x - origin_lon)//lon_step_size)\n",
    "    df['y_bucket'] = df['y'].apply(lambda y: abs(y - origin_lat)//lat_step_size)\n",
    "\n",
    "    # now, we groupby bucket and sum the level\n",
    "    grouped = df.groupby(['x_bucket', 'y_bucket']).agg({'level':'sum'}).compute()\n",
    "    grouped.reset_index(inplace=True)\n",
    "    grouped.to_csv('./bucketed/' + str(i) + '.csv', header=False, index=False)\n",
    "    \n",
    "df = pd.DataFrame(columns=['x_bucket', 'y_bucket', 'level'])\n",
    "df.set_index(['x_bucket', 'y_bucket'], inplace=True)\n",
    "\n",
    "for filename in os.listdir('./bucketed/'):\n",
    "    bucketed_df = pd.read_csv('./bucketed/' + filename, header=None, names=['x_bucket', 'y_bucket', 'level'], index_col=['x_bucket', 'y_bucket'])\n",
    "    df = df.add(bucketed_df, fill_value=0)\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df.to_csv('done.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xby.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaoag/anaconda3/lib/python3.6/site-packages/dask/dataframe/core.py:2067: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xcj.csv\n",
      "xbn.csv\n",
      "xbo.csv\n",
      "xck.csv\n",
      "xbx.csv\n",
      "xbz.csv\n",
      "xbm.csv\n",
      "xci.csv\n",
      "xch.csv\n",
      "xbl.csv\n",
      "xbh.csv\n",
      "xbi.csv\n",
      "xbk.csv\n",
      "xbj.csv\n",
      "xbg.csv\n",
      "xcc.csv\n",
      "xbp.csv\n",
      "xbq.csv\n",
      "xcb.csv\n",
      "xbs.csv\n",
      "xbr.csv\n",
      "xca.csv\n",
      "xbv.csv\n",
      "xce.csv\n",
      "xcd.csv\n",
      "xbw.csv\n",
      "xbu.csv\n",
      "xcf.csv\n",
      "xcg.csv\n",
      "xbt.csv\n"
     ]
    }
   ],
   "source": [
    "directory = './sub_items/'\n",
    "for i, filename in enumerate(os.listdir(directory)):\n",
    "    if 'DS_Store' in filename:\n",
    "        continue\n",
    "    print(filename)\n",
    "    df = dd.read_csv(directory + filename, header=None, names=['endTime', 'startTime', 'level', 'x','y'])\n",
    "    #first, we cut out all the entries in our dataframe which don't fit the desired latitude/longitude.\n",
    "    df = df[(df['y'] < max_lat) & (df['y'] > origin_lat) & (df['x'] < max_lon) & (df['x'] > origin_lon)]\n",
    "\n",
    "    #next, we assign each row an x_bucket or y_bucket based upon its latitude and longitude.\n",
    "    lon_step_size = abs(max_lon - origin_lon)/500\n",
    "    lat_step_size = abs(max_lat - origin_lat)/500\n",
    "    df['x_bucket'] = df['x'].apply(lambda x: abs(x - origin_lon)//lon_step_size)\n",
    "    df['y_bucket'] = df['y'].apply(lambda y: abs(y - origin_lat)//lat_step_size)\n",
    "\n",
    "    # now, we groupby bucket and sum the level\n",
    "    grouped = df.groupby(['x_bucket', 'y_bucket']).agg({'level':'sum'}).compute()\n",
    "    grouped.reset_index(inplace=True)\n",
    "    grouped.to_csv('./bucketed/' + str(i) + '.csv', header=False, index=False)\n",
    "    \n",
    "df = pd.DataFrame(columns=['x_bucket', 'y_bucket', 'level'])\n",
    "df.set_index(['x_bucket', 'y_bucket'], inplace=True)\n",
    "\n",
    "for filename in os.listdir('./bucketed/'):\n",
    "    bucketed_df = pd.read_csv('./bucketed/' + filename, header=None, names=['x_bucket', 'y_bucket', 'level'], index_col=['x_bucket', 'y_bucket'])\n",
    "    df = df.add(bucketed_df, fill_value=0)\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df.to_csv('done2.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xdm.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaoag/anaconda3/lib/python3.6/site-packages/dask/dataframe/core.py:2067: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xdl.csv\n",
      "xdn.csv\n",
      "xdo.csv\n",
      "xdk.csv\n",
      "xdj.csv\n",
      "xdh.csv\n",
      "xdi.csv\n",
      "xcl.csv\n",
      "xcz.csv\n",
      "xcm.csv\n",
      "xco.csv\n",
      "xcx.csv\n",
      "xcy.csv\n",
      "xcn.csv\n",
      "xct.csv\n",
      "xcu.csv\n",
      "xcw.csv\n",
      "xcv.csv\n",
      "xcr.csv\n",
      "xcs.csv\n",
      "xcq.csv\n",
      "xcp.csv\n",
      "xdd.csv\n",
      "xde.csv\n",
      "xdg.csv\n",
      "xdp.csv\n",
      "xdf.csv\n",
      "xdb.csv\n",
      "xdc.csv\n",
      "xda.csv\n"
     ]
    }
   ],
   "source": [
    "directory = './sub_items/'\n",
    "for i, filename in enumerate(os.listdir(directory)):\n",
    "    if 'DS_Store' in filename:\n",
    "        continue\n",
    "    print(filename)\n",
    "    df = dd.read_csv(directory + filename, header=None, names=['endTime', 'startTime', 'level', 'x','y'])\n",
    "    #first, we cut out all the entries in our dataframe which don't fit the desired latitude/longitude.\n",
    "    df = df[(df['y'] < max_lat) & (df['y'] > origin_lat) & (df['x'] < max_lon) & (df['x'] > origin_lon)]\n",
    "\n",
    "    #next, we assign each row an x_bucket or y_bucket based upon its latitude and longitude.\n",
    "    lon_step_size = abs(max_lon - origin_lon)/500\n",
    "    lat_step_size = abs(max_lat - origin_lat)/500\n",
    "    df['x_bucket'] = df['x'].apply(lambda x: abs(x - origin_lon)//lon_step_size)\n",
    "    df['y_bucket'] = df['y'].apply(lambda y: abs(y - origin_lat)//lat_step_size)\n",
    "\n",
    "    # now, we groupby bucket and sum the level\n",
    "    grouped = df.groupby(['x_bucket', 'y_bucket']).agg({'level':'sum'}).compute()\n",
    "    grouped.reset_index(inplace=True)\n",
    "    grouped.to_csv('./bucketed/' + str(i) + '.csv', header=False, index=False)\n",
    "    \n",
    "df = pd.DataFrame(columns=['x_bucket', 'y_bucket', 'level'])\n",
    "df.set_index(['x_bucket', 'y_bucket'], inplace=True)\n",
    "\n",
    "for filename in os.listdir('./bucketed/'):\n",
    "    bucketed_df = pd.read_csv('./bucketed/' + filename, header=None, names=['x_bucket', 'y_bucket', 'level'], index_col=['x_bucket', 'y_bucket'])\n",
    "    df = df.add(bucketed_df, fill_value=0)\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df.to_csv('done3.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xdz.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaoag/anaconda3/lib/python3.6/site-packages/dask/dataframe/core.py:2067: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xei.csv\n",
      "xeh.csv\n",
      "xdy.csv\n",
      "xej.csv\n",
      "xek.csv\n",
      "xdx.csv\n",
      "xeo.csv\n",
      "xen.csv\n",
      "xel.csv\n",
      "xem.csv\n",
      "xds.csv\n",
      "xdr.csv\n",
      "xea.csv\n",
      "xec.csv\n",
      "xdq.csv\n",
      "xeb.csv\n",
      "xeq.csv\n",
      "xdu.csv\n",
      "xef.csv\n",
      "xeg.csv\n",
      "xdt.csv\n",
      "xep.csv\n",
      "xdv.csv\n",
      "xee.csv\n",
      "xed.csv\n",
      "xdw.csv\n"
     ]
    }
   ],
   "source": [
    "directory = './sub_items/'\n",
    "for i, filename in enumerate(os.listdir(directory)):\n",
    "    if 'DS_Store' in filename:\n",
    "        continue\n",
    "    print(filename)\n",
    "    df = dd.read_csv(directory + filename, header=None, names=['endTime', 'startTime', 'level', 'x','y'])\n",
    "    #first, we cut out all the entries in our dataframe which don't fit the desired latitude/longitude.\n",
    "    df = df[(df['y'] < max_lat) & (df['y'] > origin_lat) & (df['x'] < max_lon) & (df['x'] > origin_lon)]\n",
    "\n",
    "    #next, we assign each row an x_bucket or y_bucket based upon its latitude and longitude.\n",
    "    lon_step_size = abs(max_lon - origin_lon)/500\n",
    "    lat_step_size = abs(max_lat - origin_lat)/500\n",
    "    df['x_bucket'] = df['x'].apply(lambda x: abs(x - origin_lon)//lon_step_size)\n",
    "    df['y_bucket'] = df['y'].apply(lambda y: abs(y - origin_lat)//lat_step_size)\n",
    "\n",
    "    # now, we groupby bucket and sum the level\n",
    "    grouped = df.groupby(['x_bucket', 'y_bucket']).agg({'level':'sum'}).compute()\n",
    "    grouped.reset_index(inplace=True)\n",
    "    grouped.to_csv('./bucketed/' + str(i) + '.csv', header=False, index=False)\n",
    "    \n",
    "df = pd.DataFrame(columns=['x_bucket', 'y_bucket', 'level'])\n",
    "df.set_index(['x_bucket', 'y_bucket'], inplace=True)\n",
    "\n",
    "for filename in os.listdir('./bucketed/'):\n",
    "    bucketed_df = pd.read_csv('./bucketed/' + filename, header=None, names=['x_bucket', 'y_bucket', 'level'], index_col=['x_bucket', 'y_bucket'])\n",
    "    df = df.add(bucketed_df, fill_value=0)\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df.to_csv('done4.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xfe.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaoag/anaconda3/lib/python3.6/site-packages/dask/dataframe/core.py:2067: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xfd.csv\n",
      "xff.csv\n",
      "xfg.csv\n",
      "xex.csv\n",
      "xfc.csv\n",
      "xfb.csv\n",
      "xey.csv\n",
      "xfa.csv\n",
      "xez.csv\n",
      "xew.csv\n",
      "xev.csv\n",
      "xet.csv\n",
      "xeu.csv\n",
      "xer.csv\n",
      "xfh.csv\n",
      "xes.csv\n"
     ]
    }
   ],
   "source": [
    "directory = './sub_items/'\n",
    "for i, filename in enumerate(os.listdir(directory)):\n",
    "    if 'DS_Store' in filename:\n",
    "        continue\n",
    "    print(filename)\n",
    "    df = dd.read_csv(directory + filename, header=None, names=['endTime', 'startTime', 'level', 'x','y'])\n",
    "    #first, we cut out all the entries in our dataframe which don't fit the desired latitude/longitude.\n",
    "    df = df[(df['y'] < max_lat) & (df['y'] > origin_lat) & (df['x'] < max_lon) & (df['x'] > origin_lon)]\n",
    "\n",
    "    #next, we assign each row an x_bucket or y_bucket based upon its latitude and longitude.\n",
    "    lon_step_size = abs(max_lon - origin_lon)/500\n",
    "    lat_step_size = abs(max_lat - origin_lat)/500\n",
    "    df['x_bucket'] = df['x'].apply(lambda x: abs(x - origin_lon)//lon_step_size)\n",
    "    df['y_bucket'] = df['y'].apply(lambda y: abs(y - origin_lat)//lat_step_size)\n",
    "\n",
    "    # now, we groupby bucket and sum the level\n",
    "    grouped = df.groupby(['x_bucket', 'y_bucket']).agg({'level':'sum'}).compute()\n",
    "    grouped.reset_index(inplace=True)\n",
    "    grouped.to_csv('./bucketed/' + str(i) + '.csv', header=False, index=False)\n",
    "    \n",
    "df = pd.DataFrame(columns=['x_bucket', 'y_bucket', 'level'])\n",
    "df.set_index(['x_bucket', 'y_bucket'], inplace=True)\n",
    "\n",
    "for filename in os.listdir('./bucketed/'):\n",
    "    bucketed_df = pd.read_csv('./bucketed/' + filename, header=None, names=['x_bucket', 'y_bucket', 'level'], index_col=['x_bucket', 'y_bucket'])\n",
    "    df = df.add(bucketed_df, fill_value=0)\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df.to_csv('done5.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaoag/anaconda3/lib/python3.6/site-packages/dask/dataframe/core.py:2067: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "df = dd.read_csv('./processed_errors.csv', header=None, names=['endTime', 'startTime', 'level', 'x','y'])\n",
    "#first, we cut out all the entries in our dataframe which don't fit the desired latitude/longitude.\n",
    "df = df[(df['y'] < max_lat) & (df['y'] > origin_lat) & (df['x'] < max_lon) & (df['x'] > origin_lon)]\n",
    "\n",
    "#next, we assign each row an x_bucket or y_bucket based upon its latitude and longitude.\n",
    "lon_step_size = abs(max_lon - origin_lon)/500\n",
    "lat_step_size = abs(max_lat - origin_lat)/500\n",
    "df['x_bucket'] = df['x'].apply(lambda x: abs(x - origin_lon)//lon_step_size)\n",
    "df['y_bucket'] = df['y'].apply(lambda y: abs(y - origin_lat)//lat_step_size)\n",
    "\n",
    "# now, we groupby bucket and sum the level\n",
    "grouped = df.groupby(['x_bucket', 'y_bucket']).agg({'level':'sum'}).compute()\n",
    "grouped.reset_index(inplace=True)\n",
    "grouped.to_csv('./bucketed/processed_errors_bucketed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
